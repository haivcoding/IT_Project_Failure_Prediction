{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "01d0f773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import category_encoders as ce\n",
    "\n",
    "# Load and clean the data\n",
    "data = pd.read_csv(\"Dataset_Final_v6.csv\")\n",
    "data_cleaned = data.iloc[1:].copy()\n",
    "\n",
    "# Encode features and column 'State' and split data\n",
    "label_encoder = LabelEncoder()\n",
    "data_cleaned['Country_encoded'] = label_encoder.fit_transform(data_cleaned['Country'])\n",
    "\n",
    "data_cleaned['Type_encoded'] = label_encoder.fit_transform(data_cleaned['Type'])\n",
    "\n",
    "data_cleaned['Sub-Category_encoded'] = label_encoder.fit_transform(data_cleaned['Sub-Category'])\n",
    "\n",
    "data_cleaned['Restarts_encoded'] = label_encoder.fit_transform(data_cleaned['Restarts'])\n",
    "\n",
    "data_cleaned['Cost overruns_encoded'] = label_encoder.fit_transform(data_cleaned['Cost overruns'])\n",
    "\n",
    "data_cleaned['Time overruns_encoded'] = label_encoder.fit_transform(data_cleaned['Time overruns'])\n",
    "\n",
    "data_cleaned['Content deficiency_encoded'] = label_encoder.fit_transform(data_cleaned['Content deficiency'])\n",
    "\n",
    "data_cleaned['User Involvement_encoded'] = label_encoder.fit_transform(data_cleaned['User Involvement'])\n",
    "\n",
    "data_cleaned['Executive Management_encoded'] = label_encoder.fit_transform(data_cleaned['Executive Management'])\n",
    "\n",
    "data_cleaned['Statement of Requirements_encoded'] = label_encoder.fit_transform(data_cleaned['Statement of Requirements'])\n",
    "\n",
    "data_cleaned['Planning_encoded'] = label_encoder.fit_transform(data_cleaned['Planning'])\n",
    "\n",
    "data_cleaned['Expectations_encoded'] = label_encoder.fit_transform(data_cleaned['Expectations'])\n",
    "\n",
    "data_cleaned['Requirements & Specifications_encoded'] = label_encoder.fit_transform(data_cleaned['Requirements & Specifications'])\n",
    "\n",
    "# Initialize the encoder for ordinal data\n",
    "encoder_2 = ce.OrdinalEncoder(cols=['Changing Requirements & Specifications'])\n",
    "\n",
    "# Encode the 'Changing Requirements & Specifications' column\n",
    "data_cleaned['Changing Requirements & Specifications_encoded'] = encoder_2.fit_transform(data_cleaned['Changing Requirements & Specifications'])\n",
    "\n",
    "#data_cleaned['Changing Requirements & Specifications_encoded'] = label_encoder.fit_transform(data_cleaned['Changing Requirements & Specifications'])\n",
    "\n",
    "data_cleaned['Technical Competence_encoded'] = label_encoder.fit_transform(data_cleaned['Technical Competence'])\n",
    "\n",
    "data_cleaned['Resources Availability_encoded'] = label_encoder.fit_transform(data_cleaned['Resources Availability'])\n",
    "\n",
    "data_cleaned['IT Management_encoded'] = label_encoder.fit_transform(data_cleaned['IT Management'])\n",
    "\n",
    "data_cleaned['Technical Literacy_encoded'] = label_encoder.fit_transform(data_cleaned['Technical Literacy'])\n",
    "\n",
    "data_cleaned['User satisfaction_encoded'] = label_encoder.fit_transform(data_cleaned['User satisfaction'])\n",
    "\n",
    "label_encoder_state = LabelEncoder()\n",
    "data_cleaned['State_encoded'] = label_encoder_state.fit_transform(data_cleaned['State'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf159ee",
   "metadata": {},
   "source": [
    "Start building the model with the first feature:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44975d5a",
   "metadata": {},
   "source": [
    "Predictor: 'User satisfaction'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "169616c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 72.73%\n",
      "Precision: 76.92%\n",
      "Recall: 62.50%\n",
      "F1 Score: 68.97%\n"
     ]
    }
   ],
   "source": [
    "X = data_cleaned[['User satisfaction_encoded']]\n",
    "y = data_cleaned['State_encoded']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the XGBoost classifier\n",
    "clf = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate the evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Precision: {precision * 100:.2f}%\")\n",
    "print(f\"Recall: {recall * 100:.2f}%\")\n",
    "print(f\"F1 Score: {f1 * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d77bb4",
   "metadata": {},
   "source": [
    "Predictors: 'User satisfaction', 'Technical Literacy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "edcfdbdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 78.79%\n",
      "Precision: 76.47%\n",
      "Recall: 81.25%\n",
      "F1 Score: 78.79%\n"
     ]
    }
   ],
   "source": [
    "X = data_cleaned[['User satisfaction_encoded', 'Technical Literacy_encoded']]\n",
    "y = data_cleaned['State_encoded']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the XGBoost classifier\n",
    "clf = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate the evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Precision: {precision * 100:.2f}%\")\n",
    "print(f\"Recall: {recall * 100:.2f}%\")\n",
    "print(f\"F1 Score: {f1 * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd863c6d",
   "metadata": {},
   "source": [
    "Evaluation metrics went up, meaning the model's performance has been improved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5bc4be",
   "metadata": {},
   "source": [
    "Predictors: 'User satisfaction', 'Technical Literacy', 'IT Management'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c30940cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 84.85%\n",
      "Precision: 78.95%\n",
      "Recall: 93.75%\n",
      "F1 Score: 85.71%\n"
     ]
    }
   ],
   "source": [
    "X = data_cleaned[['User satisfaction_encoded', 'Technical Literacy_encoded', 'IT Management_encoded']]\n",
    "y = data_cleaned['State_encoded']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the XGBoost classifier\n",
    "clf = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate the evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Precision: {precision * 100:.2f}%\")\n",
    "print(f\"Recall: {recall * 100:.2f}%\")\n",
    "print(f\"F1 Score: {f1 * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dad48d7",
   "metadata": {},
   "source": [
    "Evaluation metrics went up, meaning the model's performance has been improved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c24ec7",
   "metadata": {},
   "source": [
    "Predictors: 'User satisfaction', 'Technical Literacy', 'IT Management', 'Resources Availability'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "31ca854a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 81.82%\n",
      "Precision: 75.00%\n",
      "Recall: 93.75%\n",
      "F1 Score: 83.33%\n"
     ]
    }
   ],
   "source": [
    "X = data_cleaned[['User satisfaction_encoded', 'Technical Literacy_encoded', 'IT Management_encoded', 'Resources Availability_encoded']]\n",
    "y = data_cleaned['State_encoded']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the XGBoost classifier\n",
    "clf = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate the evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Precision: {precision * 100:.2f}%\")\n",
    "print(f\"Recall: {recall * 100:.2f}%\")\n",
    "print(f\"F1 Score: {f1 * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bb4cbc",
   "metadata": {},
   "source": [
    "Evaluation metrics went down, so we should not use 'Resources Availability' as a predictor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14797ab4",
   "metadata": {},
   "source": [
    "Predictors: 'User satisfaction', 'Technical Literacy', 'IT Management', 'Technical Competence'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2f57deb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 84.85%\n",
      "Precision: 78.95%\n",
      "Recall: 93.75%\n",
      "F1 Score: 85.71%\n"
     ]
    }
   ],
   "source": [
    "X = data_cleaned[['User satisfaction_encoded', 'Technical Literacy_encoded', 'IT Management_encoded', 'Technical Competence_encoded']]\n",
    "y = data_cleaned['State_encoded']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the XGBoost classifier\n",
    "clf = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate the evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Precision: {precision * 100:.2f}%\")\n",
    "print(f\"Recall: {recall * 100:.2f}%\")\n",
    "print(f\"F1 Score: {f1 * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb06dd56",
   "metadata": {},
   "source": [
    "Evaluation metrics remains unchanged, so we should not use 'Technical Competence' as a predictor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808d07ee",
   "metadata": {},
   "source": [
    "Predictors: 'User satisfaction', 'Technical Literacy', 'IT Management', 'Changing Requirements & Specifications'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f84351a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 84.85%\n",
      "Precision: 78.95%\n",
      "Recall: 93.75%\n",
      "F1 Score: 85.71%\n"
     ]
    }
   ],
   "source": [
    "X = data_cleaned[['User satisfaction_encoded', 'Technical Literacy_encoded', 'IT Management_encoded', 'Changing Requirements & Specifications_encoded']]\n",
    "y = data_cleaned['State_encoded']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the XGBoost classifier\n",
    "clf = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate the evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Precision: {precision * 100:.2f}%\")\n",
    "print(f\"Recall: {recall * 100:.2f}%\")\n",
    "print(f\"F1 Score: {f1 * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9350640",
   "metadata": {},
   "source": [
    "Evaluation metrics went up, meaning the model's performance has been improved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840d1172",
   "metadata": {},
   "source": [
    "Predictors: 'User satisfaction', 'Technical Literacy', 'IT Management', 'Changing Requirements & Specifications', 'Requirements & Specifications'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "acec5972",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.88%\n",
      "Precision: 83.33%\n",
      "Recall: 93.75%\n",
      "F1 Score: 88.24%\n"
     ]
    }
   ],
   "source": [
    "X = data_cleaned[['User satisfaction_encoded', 'Technical Literacy_encoded', 'IT Management_encoded', 'Changing Requirements & Specifications_encoded', 'Requirements & Specifications_encoded']]\n",
    "y = data_cleaned['State_encoded']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the XGBoost classifier\n",
    "clf = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate the evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Precision: {precision * 100:.2f}%\")\n",
    "print(f\"Recall: {recall * 100:.2f}%\")\n",
    "print(f\"F1 Score: {f1 * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75a958b",
   "metadata": {},
   "source": [
    "Evaluation metrics went up, meaning the model's performance has been improved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918f14c9",
   "metadata": {},
   "source": [
    "Predictors: 'User satisfaction', 'Technical Literacy', 'IT Management', 'Changing Requirements & Specifications', 'Requirements & Specifications', 'Expectations'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8d91e521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.88%\n",
      "Precision: 83.33%\n",
      "Recall: 93.75%\n",
      "F1 Score: 88.24%\n"
     ]
    }
   ],
   "source": [
    "X = data_cleaned[['User satisfaction_encoded', 'Technical Literacy_encoded', 'IT Management_encoded', 'Changing Requirements & Specifications_encoded', 'Requirements & Specifications_encoded', 'Expectations_encoded']]\n",
    "y = data_cleaned['State_encoded']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the XGBoost classifier\n",
    "clf = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate the evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Precision: {precision * 100:.2f}%\")\n",
    "print(f\"Recall: {recall * 100:.2f}%\")\n",
    "print(f\"F1 Score: {f1 * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380e1938",
   "metadata": {},
   "source": [
    "Evaluation metrics went down, so we should not use 'Expectations' as a predictor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5534d6f2",
   "metadata": {},
   "source": [
    "Predictors: 'User satisfaction', 'Technical Literacy', 'IT Management', 'Changing Requirements & Specifications', 'Requirements & Specifications', 'Planning'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "67c45e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.88%\n",
      "Precision: 83.33%\n",
      "Recall: 93.75%\n",
      "F1 Score: 88.24%\n"
     ]
    }
   ],
   "source": [
    "X = data_cleaned[['User satisfaction_encoded', 'Technical Literacy_encoded', 'IT Management_encoded', 'Changing Requirements & Specifications_encoded', 'Requirements & Specifications_encoded', 'Planning_encoded']]\n",
    "y = data_cleaned['State_encoded']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the XGBoost classifier\n",
    "clf = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate the evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Precision: {precision * 100:.2f}%\")\n",
    "print(f\"Recall: {recall * 100:.2f}%\")\n",
    "print(f\"F1 Score: {f1 * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60948b1c",
   "metadata": {},
   "source": [
    "Evaluation metrics went down, so we should not use 'Planning' as a predictor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a4118b",
   "metadata": {},
   "source": [
    "Predictors: 'User satisfaction', 'Technical Literacy', 'IT Management', 'Changing Requirements & Specifications', 'Requirements & Specifications', 'Statement of Requirements'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8fa01733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 78.79%\n",
      "Precision: 76.47%\n",
      "Recall: 81.25%\n",
      "F1 Score: 78.79%\n"
     ]
    }
   ],
   "source": [
    "X = data_cleaned[['User satisfaction_encoded', 'Technical Literacy_encoded', 'IT Management_encoded', 'Changing Requirements & Specifications_encoded', 'Requirements & Specifications_encoded', 'Statement of Requirements_encoded']]\n",
    "y = data_cleaned['State_encoded']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the XGBoost classifier\n",
    "clf = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate the evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Precision: {precision * 100:.2f}%\")\n",
    "print(f\"Recall: {recall * 100:.2f}%\")\n",
    "print(f\"F1 Score: {f1 * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656a9d5b",
   "metadata": {},
   "source": [
    "Evaluation metrics went down, so we should not use 'Statement of Requirements' as a predictor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e9d87d",
   "metadata": {},
   "source": [
    "Predictors: 'User satisfaction', 'Technical Literacy', 'IT Management', 'Changing Requirements & Specifications', 'Requirements & Specifications', 'Executive Management'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "320d5b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.88%\n",
      "Precision: 80.00%\n",
      "Recall: 100.00%\n",
      "F1 Score: 88.89%\n"
     ]
    }
   ],
   "source": [
    "X = data_cleaned[['User satisfaction_encoded', 'Technical Literacy_encoded', 'IT Management_encoded', 'Changing Requirements & Specifications_encoded', 'Requirements & Specifications_encoded', 'Executive Management_encoded']]\n",
    "y = data_cleaned['State_encoded']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the XGBoost classifier\n",
    "clf = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate the evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Precision: {precision * 100:.2f}%\")\n",
    "print(f\"Recall: {recall * 100:.2f}%\")\n",
    "print(f\"F1 Score: {f1 * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7f7b86",
   "metadata": {},
   "source": [
    "Evaluation metrics went down, so we should not use 'Executive Management' as a predictor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe44e7b",
   "metadata": {},
   "source": [
    "Predictors: 'User satisfaction', 'Technical Literacy', 'IT Management', 'Changing Requirements & Specifications', 'Requirements & Specifications', 'User Involvement'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "231929a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.88%\n",
      "Precision: 80.00%\n",
      "Recall: 100.00%\n",
      "F1 Score: 88.89%\n"
     ]
    }
   ],
   "source": [
    "X = data_cleaned[['User satisfaction_encoded', 'Technical Literacy_encoded', 'IT Management_encoded', 'Changing Requirements & Specifications_encoded', 'Requirements & Specifications_encoded', 'User Involvement_encoded']]\n",
    "y = data_cleaned['State_encoded']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the XGBoost classifier\n",
    "clf = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate the evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Precision: {precision * 100:.2f}%\")\n",
    "print(f\"Recall: {recall * 100:.2f}%\")\n",
    "print(f\"F1 Score: {f1 * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba708a7",
   "metadata": {},
   "source": [
    "Evaluation metrics went down, so we should not use 'User Involvement' as a predictor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f41c87",
   "metadata": {},
   "source": [
    "Predictors: 'User satisfaction', 'Technical Literacy', 'IT Management', 'Changing Requirements & Specifications', 'Requirements & Specifications', 'Content deficiency'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "14f26686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 90.91%\n",
      "Precision: 88.24%\n",
      "Recall: 93.75%\n",
      "F1 Score: 90.91%\n"
     ]
    }
   ],
   "source": [
    "X = data_cleaned[['User satisfaction_encoded', 'Technical Literacy_encoded', 'IT Management_encoded', 'Changing Requirements & Specifications_encoded', 'Requirements & Specifications_encoded', 'Content deficiency_encoded']]\n",
    "y = data_cleaned['State_encoded']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the XGBoost classifier\n",
    "clf = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate the evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Precision: {precision * 100:.2f}%\")\n",
    "print(f\"Recall: {recall * 100:.2f}%\")\n",
    "print(f\"F1 Score: {f1 * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aaa94b0",
   "metadata": {},
   "source": [
    "Evaluation metrics went up, meaning the model's performance has been improved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3067231c",
   "metadata": {},
   "source": [
    "Predictors: 'User satisfaction', 'Technical Literacy', 'IT Management', 'Changing Requirements & Specifications', 'Requirements & Specifications', 'Content deficiency', 'Time overruns'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8704e090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 84.85%\n",
      "Precision: 76.19%\n",
      "Recall: 100.00%\n",
      "F1 Score: 86.49%\n"
     ]
    }
   ],
   "source": [
    "X = data_cleaned[['User satisfaction_encoded', 'Technical Literacy_encoded', 'IT Management_encoded', 'Changing Requirements & Specifications_encoded', 'Requirements & Specifications_encoded', 'Content deficiency_encoded',  'Time overruns_encoded']]\n",
    "y = data_cleaned['State_encoded']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the XGBoost classifier\n",
    "clf = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate the evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Precision: {precision * 100:.2f}%\")\n",
    "print(f\"Recall: {recall * 100:.2f}%\")\n",
    "print(f\"F1 Score: {f1 * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d42823",
   "metadata": {},
   "source": [
    "Evaluation metrics went down, so we should not use 'Time overruns' as a predictor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b23dcb5",
   "metadata": {},
   "source": [
    "Predictors: 'User satisfaction', 'Technical Literacy', 'IT Management', 'Changing Requirements & Specifications', 'Requirements & Specifications', 'Content deficiency', 'Cost overruns'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e7d8a400",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.88%\n",
      "Precision: 83.33%\n",
      "Recall: 93.75%\n",
      "F1 Score: 88.24%\n"
     ]
    }
   ],
   "source": [
    "X = data_cleaned[['User satisfaction_encoded', 'Technical Literacy_encoded', 'IT Management_encoded', 'Changing Requirements & Specifications_encoded', 'Requirements & Specifications_encoded', 'Content deficiency_encoded', 'Cost overruns_encoded']]\n",
    "y = data_cleaned['State_encoded']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the XGBoost classifier\n",
    "clf = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate the evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Precision: {precision * 100:.2f}%\")\n",
    "print(f\"Recall: {recall * 100:.2f}%\")\n",
    "print(f\"F1 Score: {f1 * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45624ebd",
   "metadata": {},
   "source": [
    "Evaluation metrics remain unchanged, so we should not use 'Cost overruns' as a predictor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cab603",
   "metadata": {},
   "source": [
    "Predictors: 'User satisfaction', 'Technical Literacy', 'IT Management', 'Changing Requirements & Specifications', 'Requirements & Specifications', 'Content deficiency', 'Restarts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "139160d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 84.85%\n",
      "Precision: 82.35%\n",
      "Recall: 87.50%\n",
      "F1 Score: 84.85%\n"
     ]
    }
   ],
   "source": [
    "X = data_cleaned[['User satisfaction_encoded', 'Technical Literacy_encoded', 'IT Management_encoded', 'Changing Requirements & Specifications_encoded', 'Requirements & Specifications_encoded', 'Content deficiency_encoded', 'Restarts_encoded']]\n",
    "y = data_cleaned['State_encoded']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the XGBoost classifier\n",
    "clf = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate the evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Precision: {precision * 100:.2f}%\")\n",
    "print(f\"Recall: {recall * 100:.2f}%\")\n",
    "print(f\"F1 Score: {f1 * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0251d1f",
   "metadata": {},
   "source": [
    "Evaluation metrics went down, so we should not use 'Restarts' as a predictor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cf7292",
   "metadata": {},
   "source": [
    "Predictors: 'User satisfaction', 'Technical Literacy', 'IT Management', 'Changing Requirements & Specifications', 'Requirements & Specifications', 'Content deficiency', 'Duration (Years)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6d61d9e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 90.91%\n",
      "Precision: 88.24%\n",
      "Recall: 93.75%\n",
      "F1 Score: 90.91%\n"
     ]
    }
   ],
   "source": [
    "X = data_cleaned[['User satisfaction_encoded', 'Technical Literacy_encoded', 'IT Management_encoded', 'Changing Requirements & Specifications_encoded', 'Requirements & Specifications_encoded', 'Content deficiency_encoded', 'Duration (Years)']]\n",
    "y = data_cleaned['State_encoded']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the XGBoost classifier\n",
    "clf = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate the evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Precision: {precision * 100:.2f}%\")\n",
    "print(f\"Recall: {recall * 100:.2f}%\")\n",
    "print(f\"F1 Score: {f1 * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bbc631",
   "metadata": {},
   "source": [
    "Evaluation metrics went down, so we should not use 'Duration (Years)' as a predictor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81758874",
   "metadata": {},
   "source": [
    "Predictors: 'User satisfaction', 'Technical Literacy', 'IT Management', 'Changing Requirements & Specifications', 'Requirements & Specifications', 'Content deficiency', 'Sub-Category'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dbba6bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.88%\n",
      "Precision: 87.50%\n",
      "Recall: 87.50%\n",
      "F1 Score: 87.50%\n"
     ]
    }
   ],
   "source": [
    "X = data_cleaned[['User satisfaction_encoded', 'Technical Literacy_encoded', 'IT Management_encoded', 'Changing Requirements & Specifications_encoded', 'Requirements & Specifications_encoded', 'Content deficiency_encoded', 'Sub-Category_encoded']]\n",
    "y = data_cleaned['State_encoded']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the XGBoost classifier\n",
    "clf = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate the evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Precision: {precision * 100:.2f}%\")\n",
    "print(f\"Recall: {recall * 100:.2f}%\")\n",
    "print(f\"F1 Score: {f1 * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3c2298",
   "metadata": {},
   "source": [
    "Evaluation metrics went down, so we should not use 'Sub-Category' as a predictor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8473b1",
   "metadata": {},
   "source": [
    "Predictors: 'User satisfaction', 'Technical Literacy', 'IT Management', 'Changing Requirements & Specifications', 'Requirements & Specifications', 'Content deficiency', 'Type'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a842c164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 90.91%\n",
      "Precision: 84.21%\n",
      "Recall: 100.00%\n",
      "F1 Score: 91.43%\n"
     ]
    }
   ],
   "source": [
    "X = data_cleaned[['User satisfaction_encoded', 'Technical Literacy_encoded', 'IT Management_encoded', 'Changing Requirements & Specifications_encoded', 'Requirements & Specifications_encoded', 'Content deficiency_encoded', 'Type_encoded']]\n",
    "y = data_cleaned['State_encoded']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the XGBoost classifier\n",
    "clf = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate the evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Precision: {precision * 100:.2f}%\")\n",
    "print(f\"Recall: {recall * 100:.2f}%\")\n",
    "print(f\"F1 Score: {f1 * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9032a82d",
   "metadata": {},
   "source": [
    "Evaluation metrics went down, so we should not use 'Type' as a predictor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8b2247",
   "metadata": {},
   "source": [
    "Predictors: 'User satisfaction', 'Technical Literacy', 'IT Management', 'Changing Requirements & Specifications', 'Requirements & Specifications', 'Content deficiency', 'Country'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "da880a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.88%\n",
      "Precision: 83.33%\n",
      "Recall: 93.75%\n",
      "F1 Score: 88.24%\n"
     ]
    }
   ],
   "source": [
    "X = data_cleaned[['User satisfaction_encoded', 'Technical Literacy_encoded', 'IT Management_encoded', 'Changing Requirements & Specifications_encoded', 'Requirements & Specifications_encoded', 'Content deficiency_encoded', 'Country_encoded']]\n",
    "y = data_cleaned['State_encoded']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the XGBoost classifier\n",
    "clf = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate the evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "f1 = f1_score(y_test, y_pred, pos_label=1)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
    "print(f\"Precision: {precision * 100:.2f}%\")\n",
    "print(f\"Recall: {recall * 100:.2f}%\")\n",
    "print(f\"F1 Score: {f1 * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a07fec",
   "metadata": {},
   "source": [
    "Evaluation metrics went down, so we should not use 'Country' as a predictor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc4ce51",
   "metadata": {},
   "source": [
    "In conclusion, the best model was built with these features: 'User satisfaction', 'Technical Literacy', 'IT Management', 'Changing Requirements & Specifications', 'Requirements & Specifications', 'Content deficiency'.\n",
    "\n",
    "Evaluation metrics:\n",
    "\n",
    "Accuracy: 90.91%\n",
    "\n",
    "Precision: 88.24%\n",
    "\n",
    "Recall: 93.75%\n",
    "\n",
    "F1 Score: 90.91%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
